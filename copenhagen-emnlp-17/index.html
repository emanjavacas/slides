<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Assessing the Stylistic Properties of Neurally Generated Text in Authorship Attribution</title>
<meta name="author" content="(Enrique Manjavacas & Jeroen De Gussem & Walter Daelemans & Mike Kestemont)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="../externals/reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="../externals/reveal.js/css/theme/solarized.css" id="theme"/>

<link rel="stylesheet" href="./extra_emnlp17.css"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = '../externals/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1>Assessing the Stylistic Properties of Neurally Generated Text in Authorship Attribution</h1><h2>Enrique Manjavacas &amp; Jeroen De Gussem &amp; Walter Daelemans &amp; Mike Kestemont</h2><h4>08/09/2017</h4><h4>EMNLP17 (Workshop on Stylistic Variation) - Copenhagen</h4><p><a href="https://emanjavacas.github.com/slides-content/copenhagen-emnlp-17">https://emanjavacas.github.com/slides-content/copenhagen-emnlp-17</a></p>
</section>

<section>
<section id="slide-org5fc1105">
<h2 id="org5fc1105"><span class="section-number-2">1</span> Introduction</h2>
<aside class="notes">
<ul>
<li>In this talk we present work on evaluating neurally generated text with respect to its capacity to preserve authorial style.</li>

</ul>

</aside>

</section>
<section id="slide-org0db25aa">
<h3 id="org0db25aa">RNNs are a powerful tool for text generation</h3>
<aside class="notes">
<ul>
<li>Anecdotical: Famous pieces is the popular blog post by A. Karpathy and its many follow-ups.</li>
<li>Only recently have we started to see more thorough studies on the linguistic information encoded in RNNs</li>

</ul>

</aside>
<ul>
<li class="fragment roll-in">Neurally generated text makes an authentic impression on readers</li>
<li class="fragment roll-in">Basis for renewed interest in NLG</li>
<li class="fragment roll-in">Recent interest in the information encoded by RNNs</li>

</ul>

</section>
<section id="slide-orge2024e4">
<h3 id="orge2024e4">Evaluation of neural synthetic text through Authorship Attribution</h3>
<aside class="notes">
<p>
For contrast, we wanted to study the potential of RNNs in comparison to traditional NGram models
</p>

</aside>
<ul>
<li class="fragment roll-in">To what extent does the generative model retain author-related stylistic properties of the source?</li>
<li class="fragment roll-in">How does it compare to traditional n-gram models?</li>

</ul>

</section>
<section id="slide-orgd39c288">
<h3 id="orgd39c288">Experiment idea</h3>
<aside class="notes">
<p>
Very simple idea. Allows for many variations (evaluate different models, use different attributors)
</p>

</aside>
<ul>
<li class="fragment roll-in">Fit Language Models (one per author)</li>
<li class="fragment roll-in">Generate a collection of docs per author through sampling</li>
<li class="fragment roll-in">Apply AA to the resulting synthetic dataset</li>

</ul>

</section>
<section id="slide-org5c44443">
<h4 id="org5c44443">Assumptions</h4>
<aside class="notes">
<p>
Controversial, but used as a symplifying assumption to get going.
Of course, we could bias the algorithm towards more proper stylistic properties.
</p>

</aside>
<p class="fragment (roll-in)">
&ldquo;Algorithmic&rdquo; definition of style
</p>
<blockquote  class="fragment (roll-in)">
<p>
Style is whatever textual properties an algorithm might use in order to successfully 
attribute a text to its actual author, without considering whether the
properties discovered by the algorithm are stylistic in a narrower sense.
</p>
</blockquote>

</section>
</section>
<section>
<section id="slide-orgb251636">
<h2 id="orgb251636"><span class="section-number-2">2</span> Summary of the presentation</h2>
<ul>
<li class="fragment roll-in">Describe the models used for generation</li>
<li class="fragment roll-in">Describe the experimental setup</li>
<li class="fragment roll-in">Discuss the results</li>

</ul>

</section>
</section>
<section>
<section id="slide-org4e734b6">
<h2 id="org4e734b6"><span class="section-number-2">3</span> Text Generation</h2>
<aside class="notes">
<p>
We approach the task of text generation with simple language models.
We use character-level for simplicity and to tackle sparsity. However:
</p>
<ul>
<li>OOV during generation</li>
<li>Credit assignment paths span smaller linguistic sequences</li>

</ul>

</aside>

</section>
<section id="slide-org411750d">
<h3 id="org411750d">Character-level Text Generation with Language Models</h3>
<aside class="notes">
<p>
As a recap
</p>

</aside>

<p>
<span class="fragment highlight-green">        \(P(w_1, w_2, ..., w_n)\) =
</span><span class="fragment highlight-green"> \(P(w_1|\text{<}bos\text{>})\)
</span><span class="fragment highlight-green"> \(* \prod_{i=1}^n P(w_{i+1}|w_1, ..., w_{i})\)
</span>
</p>

</section>
<section id="slide-orgdfc3d07">
<h4 id="orgdfc3d07">Sample &ldquo;n&rdquo; characters from the Language Model</h4>
<ul>
<li class="fragment roll-in">\(w_1 \sim P(w|\text{<}bos\text{>})\)</li>
<li class="fragment roll-in">\(w_2 \sim P(w|\text{<}bos\text{>}, w_1)\)</li>
<li class="fragment roll-in">\(\ldots\)</li>
<li class="fragment roll-in">\(w_n \sim P(w|\text{<}bos\text{>}, w_1, ..., w_{n-1})\)</li>

</ul>

</section>
<section id="slide-orgd6aeab4">
<h4 id="orgd6aeab4">Multinomial sampling with temperature</h4>
<ul>
<li class="fragment roll-in">\(P(w|\text{<}bos\text{>}) = \{p_1, p_2, ..., p_v\}\)</li>
<li class="fragment roll-in">\(p_i^{\tau} = \frac{p_i / \tau}{\sum_j^V p_j / \tau}\)</li>

</ul>

</section>
<section id="slide-org92a124f">
<h3 id="org92a124f">Models</h3>
<div class="outline-text-3" id="text-org92a124f">
</div></section>
<section id="slide-org4f8c725">
<h4 id="org4f8c725">NGLM</h4>
<aside class="notes">
<p>
Introduce Markov Assumption
</p>

</aside>

<p>
\(P(w_t|\ldots)\) <span class="fragment fade-in"> \(\approx P(w_t|w_{t-(n+1)}, \ldots, w_{t-1})\) </span>
</p>

</section>
<section id="slide-org8d9543e">
<h4 id="org8d9543e">RNNLM</h4>

<div class="figure">
<p><object type="image/svg+xml" data="./img/rnnlm.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>

</section>
</section>
<section>
<section id="slide-orgdcd4d51">
<h2 id="orgdcd4d51"><span class="section-number-2">4</span> Experiment</h2>
<div class="outline-text-2" id="text-4">
</div></section>
<section id="slide-orgdef2157">
<h3 id="orgdef2157">Experimental Setup</h3>
<div class="outline-text-3" id="text-orgdef2157">
</div></section>
<section id="slide-orgafb6124">
<h4 id="orgafb6124">Difficulties</h4>
<p>
Maximize comparability of authentic and generated text
</p>
<ul>
<li class="fragment roll-in">Unequal training size per author for LMs</li>
<li class="fragment roll-in">Unequal training and test size per author for the attributor (important in AA)</li>
<li class="fragment roll-in">Authentic text has doc-level structure, LM-generated text does not</li>

</ul>

</section>
<section id="slide-org1d23952">
<h4 id="org1d23952">Proposed method</h4>
<ul>
<li class="fragment roll-in">Random even doc-level split (referred to as \(\alpha\) and \(\omega\) for simplicity)</li>
<li class="fragment roll-in">Create 20 fixed-size (5000w) docs per split by sampling sentences</li>
<li class="fragment roll-in">Sample a third set (\(\bar{\alpha}\)) from the author&rsquo;s LMs trained on \(\alpha\)</li>

</ul>

</section>
<section id="slide-orgcc2210d">
<h4 id="orgcc2210d">Attribution Experiments</h4>
<aside class="notes">
<ul>
<li>Defines 5 experiments</li>
<li>Requires training only 3 classifiers (one per dataset)</li>
<li>Account for directionality effects</li>

</ul>

</aside>

<img src="./img/setup.svg">

</section>
<section id="slide-org96cc462">
<h3 id="org96cc462">Dataset</h3>
<aside class="notes">
<p>
We only used 18 * 100,000 * 2 (= 4M words)
</p>

</aside>
<ul>
<li class="fragment roll-in">Patrologia Latina (⩲ 113M words)</li>
<li class="fragment roll-in">Ecclesiastical latin texts spanning 1000 years</li>
<li class="fragment roll-in">Homogeneous institutionalized literary language (L2 language)</li>

</ul>

</section>
<section >
<img src="./img/author_words_docs.svg">

</section>
<section id="slide-org04f778c">
<h3 id="org04f778c">Language Model Fitting</h3>
<div class="outline-text-3" id="text-org04f778c">
</div></section>
<section id="slide-orga199967">
<h4 id="orga199967">NGLM</h4>
<ul>
<li class="fragment roll-in">N-gram order is set to 6</li>
<li class="fragment roll-in">Parameters estimated through MLE (no smoothing since only interested in generation)</li>

</ul>

</section>
<section id="slide-org379b23f">
<h4 id="org379b23f">RNNLM</h4>
<p>
Model definition
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment (roll-in)">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Parameter</th>
<th scope="col" class="org-right">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Embedding size</td>
<td class="org-right">24</td>
</tr>

<tr>
<td class="org-left">RNN Cell</td>
<td class="org-right">LSTM</td>
</tr>

<tr>
<td class="org-left">Hidden size</td>
<td class="org-right">200</td>
</tr>

<tr>
<td class="org-left">Hidden Layers</td>
<td class="org-right">2</td>
</tr>
</tbody>
</table>

</section>
<section >
<p>
Training
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment (roll-in)">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Parameter</th>
<th scope="col" class="org-right">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Batch size</td>
<td class="org-right">50</td>
</tr>

<tr>
<td class="org-left">Optimizer</td>
<td class="org-right">Adam (default params)</td>
</tr>

<tr>
<td class="org-left">Learning rate</td>
<td class="org-right">0.001</td>
</tr>

<tr>
<td class="org-left">Gradient norm clipping</td>
<td class="org-right">5.0</td>
</tr>

<tr>
<td class="org-left">Dropout</td>
<td class="org-right">0.3 (RNN output)</td>
</tr>

<tr>
<td class="org-left">Epochs</td>
<td class="org-right">50</td>
</tr>
</tbody>
</table>

</section>
<section >
<p>
Validation perplexity: <span class="fragment highlight-green"><strong>4.015 (± 0.183)</strong></span>
</p>

</section>
<section id="slide-org1de6717">
<h3 id="org1de6717">Attributor</h3>
<aside class="notes">
<ul>
<li>max-features: ordered by term-freq</li>
<li>small grid, since computationally expensive (5-fold CV + 7 experiments)</li>

</ul>

</aside>
<ul>
<li class="fragment roll-in">Linear SVM (scikit-learn) on tf-idf character {2,3,4}-grams</li>
<li class="fragment roll-in">No word-level features since RNN can produce unseen words</li>
<li class="fragment roll-in">Grid-search over parameters</li>

</ul>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment (roll-in)">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Parameter</th>
<th scope="col" class="org-left">Grid values</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Max-features</td>
<td class="org-left">5,000; 10,000; 15,000; 30,000</td>
</tr>

<tr>
<td class="org-left">C</td>
<td class="org-left">1; 10; 100; 1,000</td>
</tr>
</tbody>
</table>

</section>
</section>
<section>
<section id="slide-org9f0160c">
<h2 id="org9f0160c"><span class="section-number-2">5</span> Results</h2>
<p>
5-fold cross-validated scores per experiment
</p>

</section>
<section id="slide-orgd81c522">
<h3 id="orgd81c522">Numbers</h3>
<aside class="notes">
<ul>
<li>Very small directionality effect (confirm no artifacts from split)</li>
<li>Training on generated data: drops considerably (both NGLM and RNNLM)</li>
<li>Training on real data: improvement on NGLM, still drop for the RNN</li>

</ul>

</aside>

<div class="table">

<!--l. 5--><p class="indent" >   <hr class="float"><div class="float" 
>

<!--tex4ht:inline--><div class="tabular">
 <table id="TBL-1" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-1-1g"><col 
id="TBL-1-1"><col 
id="TBL-1-2"><col 
id="TBL-1-3"><col 
id="TBL-1-4"><col 
id="TBL-1-5"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-1-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-1"  
class="td11">Source  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-2"  
class="td11">Experiment</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-3"  
class="td11"> F1  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-4"  
class="td11">  P  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-5"  
class="td11"> R  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-1"  
class="td11">Real     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha;,&omega; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-3"  
class="td11">0.833</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-4"  
class="td11">0.818</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-5"  
class="td11">0.869</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,&alpha; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-3"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-4"  
class="td11">0.795</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-5"  
class="td11">0.853</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-1"  
class="td11">NGLM  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-3"  
class="td11">0.706</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-4"  
class="td11">0.744</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-5"  
class="td11">0.750</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-3"  
class="td11">0.837</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-4"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-5"  
class="td11">0.881</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-1"  
class="td11">RNNLM</td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-3"  
class="td11">0.635</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-4"  
class="td11">0.701</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-5"  
class="td11">0.658</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-3"  
class="td11">0.724</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-4"  
class="td11">0.778</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-5"  
class="td11">0.775</td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-8-1"  
class="td11">       </td></tr></table></div>

   </div><hr class="endfloat" />
   </div>

</section>
<section id="slide-org3a4d202">
<h3 id="org3a4d202">Discussion</h3>
<div class="outline-text-3" id="text-org3a4d202">
</div></section>
<section id="slide-org75db56c">
<h4 id="org75db56c">Why does NGLM outperforms RNNLM in both setups (\(<\bar{\alpha},\omega>, <\omega,\bar{\alpha}>\))?</h4>
<p class="fragment (roll-in)">
SVM uses very local features, NGLM reproduces very well the local distribution
</p>

<aside class="notes">
<ul>
<li>Use local information (ngrams) to visualize the difference between real and generated distributions.</li>

</ul>

</aside>

</section>
<section >
<aside class="notes">
<ul>
<li>jaccard: intersection / union</li>
<li>We compute the lexical overlap across each author&rsquo;s generated and real documents using Jaccard similarity</li>
<li>For comparison we also compute the lexical overlap across authors</li>
<li>We expect a certain overlap for any author, and less overlap across authors</li>

</ul>

</aside>
<p>
LEXICAL OVERLAP: Mean-normalized ngram Jaccard-similarity across authors.
</p>

<p>
<span class="fragment fade-in"><strong>Character-level</strong><br/><img src="./img/jaccard_mean_char.svg"></span>
</p>

</section>
<section >
<aside class="notes">
<ul>
<li>Interestingly, we obtain a very similar picture at a higher-level (word-level)</li>

</ul>

</aside>
<p>
LEXICAL OVERLAP: Mean-normalized Jaccard-similarity on author ngrams
</p>

<p>
<span class=""><p><strong>Word-level</strong></p><img src="./img/jaccard_mean.svg"></span>
</p>

</section>
<section >
<aside class="notes">
<ul>
<li>For 3 authors, we take real and generated documents</li>
<li>Represent the documents using 150 most frequente char ngrams</li>
<li>Apply PCA to visualize the documents in space (for clustering)</li>
<li>We observe that this representation based on local features puts real and NGLM-generated text together</li>

</ul>

</aside>
<p>
DOC-LEVEL PCA: <b>NGLM</b> (150 most-freq ngrams doc-representation)
</p>
<img src="./img/nglm_pca.svg">

</section>
<section >
<aside class="notes">
<ul>
<li>Clustering based on local features separates real and RNNLM-generated in some cases</li>
<li>Reveals certain fuzzyness in the RNNLM-generated text</li>

</ul>

</aside>
<p>
DOC-LEVEL PCA: <b>RNNLM</b> (150 most-freq ngrams doc-representation)
</p>
<img src="./img/rnnlm_pca.svg">


</section>
<section id="slide-orgaece4ca">
<h4 id="orgaece4ca">Why does NGLM outperforms Real setup in (\(\omega\), \(\alpha\))?</h4>
<aside class="notes">
<p>
We haven&rsquo;t done any further analysis but judging on the basis of the previous viz
</p>

</aside>
<ul>
<li class="fragment roll-in">Prunning effect? Eliminating &ldquo;distractive&rdquo; features and enhancing those that are more relevant</li>
<li class="fragment roll-in">It might prove beneficial for actual AA</li>

</ul>


</section>
</section>
<section>
<section id="slide-orgc72909d">
<h2 id="orgc72909d"><span class="section-number-2">6</span> Self-learning (Data-augmentation) Experiments</h2>
<aside class="notes">
<p>
We were not satisfied, since RNNLM should have an advantage on modelling style, even though we only use very local feature to assess it.
</p>

</aside>

<ul>
<li class="fragment roll-in">Is there still some authorial signal in the RNNLM-generated data?</li>
<li class="fragment roll-in">Is there an effect of the long-term dependencies learned by the RNNLM on the stylistic properties of the generated data?</li>
<li class="fragment roll-in">If so, augmenting the authentic training data with RNNLM-generated data <span class="underline">could</span> yield attribution improvements</li>

</ul>


</section>
<section id="slide-org5a20b99">
<h3 id="org5a20b99">Experiment</h3>
<aside class="notes">
<p>
For each author, concatenate authentic document collection with the generated one.
</p>

</aside>

<p class="fragment (roll-in)">
\(<\alpha+\bar{\alpha}, \omega>\)
</p>

</section>
<section id="slide-org63cf30c">
<h3 id="org63cf30c">Numbers</h3>
<aside class="notes">
<ul>
<li>RNNLM increases (even over the &lt;$&alpha;, &omega;$&gt; baseline)</li>
<li>NGLM increases with respect to its baseline, but not over the real baseline</li>

</ul>

</aside>

<div id="table-full">
<div class="table">

<!--l. 5--><p class="indent" >   <hr class="float"><div class="float" 
>

<!--tex4ht:inline--><div class="tabular">
 <table id="TBL-1" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-1-1g"><col 
id="TBL-1-1"><col 
id="TBL-1-2"><col 
id="TBL-1-3"><col 
id="TBL-1-4"><col 
id="TBL-1-5"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-1-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-1"  
class="td11">Source  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-2"  
class="td11">Experiment  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-3"  
class="td11"> F1  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-4"  
class="td11">  P  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-5"  
class="td11"> R  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-1"  
class="td11">Real     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha;,&omega; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-3"  
class="td11">0.833</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-4"  
class="td11">0.818</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-5"  
class="td11">0.869</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,&alpha; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-3"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-4"  
class="td11">0.795</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-5"  
class="td11">0.853</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-1"  
class="td11">NGLM  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha; </span>+ <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;</span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-3"  
class="td11">0.814</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-4"  
class="td11">0.809</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-5"  
class="td11">0.850</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-3"  
class="td11">0.706</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-4"  
class="td11">0.744</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-5"  
class="td11">0.750</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-3"  
class="td11">0.837</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-4"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-5"  
class="td11">0.881</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-1"  
class="td11">RNNLM</td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha; </span>+ <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;</span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-3"  
class="td11">0.872</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-4"  
class="td11">0.878</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-5"  
class="td11">0.892</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-8-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-8-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-8-3"  
class="td11">0.635</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-8-4"  
class="td11">0.701</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-8-5"  
class="td11">0.658</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-9-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-9-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-9-3"  
class="td11">0.724</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-9-4"  
class="td11">0.778</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-9-5"  
class="td11">0.775</td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-10-1"  
class="td11">       </td></tr></table></div>

   </div><hr class="endfloat" />
   </div>
</div>

</section>
<section >
<aside class="notes">
<ul>
<li>Effect seems to be skewing the f1 distribution towards the top</li>
<li>Rescueing some helplessly mislabeled authors (helping the attribution of some guys)</li>

</ul>

</aside>

<img src="./img/f1_sampled.svg">

</section>
<section id="slide-org0774f96">
<h3 id="org0774f96">Discussion</h3>
<aside class="notes">
<p>
To summarize the argument
</p>

</aside>
<p class="fragment (roll-in)">
-&gt; The long-term dependencies prove beneficial (not redundant)
</p>
<p class="fragment (roll-in)">
-&gt; (Evidence for) RNNLM better modelling stylistic variation in the original distribution
</p>

</section>
</section>
<section>
<section id="slide-orge41768b">
<h2 id="orge41768b"><span class="section-number-2">7</span> Conclusion</h2>
<aside class="notes">
<p>
Shortcomings:
</p>
<ul>
<li>Grid-search instead of random-search</li>
<li>Further fine-tuning of the networks (pretraining + overfitting?)</li>
<li>More compact models (CLMs (VAEs), multiheaded, &#x2026;)</li>

</ul>

</aside>

<ul>
<li>LMs seem to capture stylistic properties to a certain extent</li>
<li>More global attributors still needed. Stylistic evaluation still too local</li>
<li>Unexpected result: data-augmentation/self-learning with RNNLMs possibly beneficial</li>

</ul>

</section>
</section>
<section>
<section id="slide-org2604749">
<h2 id="org2604749"><span class="section-number-2">8</span> Thank you for your attention</h2>
</section>
</section>
</div>
</div>
<script src="../externals/reveal.js/lib/js/head.min.js"></script>
<script src="../externals/reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: true,
center: true,
slideNumber: 'c',
rollingLinks: true,
keyboard: true,
overview: true,
width: 1200,
height: 800,
margin: 0.05,
minScale: 0.50,
maxScale: 2.50,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'slide', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'fast',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: '../externals/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
 { src: '../externals/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '../externals/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '../externals/reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: '../externals/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
});
</script>
</body>
</html>
