<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Assessing the Stylistic Properties of Neurally Generated Text in Authorship Attribution</title>
<meta name="author" content="(Enrique Manjavacas & Jeroen De Gussem & Walter Daelemans & Mike Kestemont)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="../externals/reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="../externals/reveal.js/css/theme/solarized.css" id="theme"/>

<link rel="stylesheet" href="./extra_emnlp17.css"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = '../externals/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1>Assessing the Stylistic Properties of Neurally Generated Text in Authorship Attribution</h1><h2>Enrique Manjavacas &amp; Jeroen De Gussem &amp; Walter Daelemans &amp; Mike Kestemont</h2><h4>08/09/2017</h4><h4>EMNLP17 (Workshop on Stylistic Variation) - Copenhagen</h4><p><a href="https://emanjavacas.github.com/slides-content/copenhagen-emnlp-17">https://emanjavacas.github.com/slides-content/copenhagen-emnlp-17</a></p>
</section>

<section>
<section id="slide-org14b16f7">
<h2 id="org14b16f7"><span class="section-number-2">1</span> Introduction</h2>
<aside class="notes">
<ul>
<li>In this talk we present work on evaluating neurally generated text with respect to its capacity to preserve authorial style.</li>

</ul>

</aside>

</section>
<section id="slide-org3fd0004">
<h3 id="org3fd0004">RNNs are a powerful tool for text generation</h3>
<aside class="notes">
<ul>
<li>Anecdotical: Famous pieces is the popular blog post by A. Karpathy and its many follow-ups.</li>
<li>Only recently have we started to see more thorough studies on the linguistic information encoded in RNNs</li>

</ul>

</aside>
<ul>
<li class="fragment roll-in">Neurally generated text makes an authentic impression on readers</li>
<li class="fragment roll-in">Basis for renewed interest in NLG</li>
<li class="fragment roll-in">Recent interest in the information encoded by RNNs</li>

</ul>

</section>
<section id="slide-org3c9e776">
<h3 id="org3c9e776">Evaluation of neural synthetic text through Authorship Attribution</h3>
<aside class="notes">
<p>
For contrast, we wanted to study the potential of RNNs in comparison to traditional NGram models
</p>

</aside>
<ul>
<li class="fragment roll-in">To what extent does the generative model retain author-related stylistic properties of the source?</li>
<li class="fragment roll-in">How does it compare to traditional n-gram models?</li>

</ul>

</section>
<section id="slide-orge9829a6">
<h3 id="orge9829a6">Experiment idea</h3>
<aside class="notes">
<p>
Very simple idea. Allows for many variations (evaluate different models, use different attributors)
</p>

</aside>
<ul>
<li class="fragment roll-in">Fit Language Models (one per author)</li>
<li class="fragment roll-in">Generate a collection of docs per author through sampling</li>
<li class="fragment roll-in">Apply Authorship Attribution (AA) to the resulting synthetic dataset</li>

</ul>

</section>
<section id="slide-orgdc4be25">
<h4 id="orgdc4be25">Assumption</h4>
<aside class="notes">
<p>
Controversial, but used as a symplifying assumption to get going.
Of course, we could bias the algorithm towards more proper stylistic properties.
</p>

</aside>
<p class="fragment (roll-in)">
&ldquo;Algorithmic&rdquo; definition of style
</p>
<blockquote  class="fragment (roll-in)">
<p>
Style is whatever textual properties an algorithm might use in order to successfully 
attribute a text to its actual author, without considering whether the
properties discovered by the algorithm are stylistic in a narrower sense.
</p>
</blockquote>

</section>
</section>
<section>
<section id="slide-org9dcc94b">
<h2 id="org9dcc94b"><span class="section-number-2">2</span> Summary of the presentation</h2>
<ul>
<li class="fragment roll-in">Describe the models used for text generation</li>
<li class="fragment roll-in">Describe the experimental setup</li>
<li class="fragment roll-in">Discuss the results</li>

</ul>

</section>
</section>
<section>
<section id="slide-org352ce96">
<h2 id="org352ce96"><span class="section-number-2">3</span> Text Generation</h2>
<aside class="notes">
<p>
We approach the task of text generation with simple language models.
We use character-level for simplicity and to tackle sparsity. However:
</p>
<ul>
<li>OOV during generation</li>
<li>Credit assignment paths span smaller linguistic sequences</li>

</ul>

</aside>

</section>
<section id="slide-orgb89bc37">
<h3 id="orgb89bc37">Character-level Text Generation with Language Models</h3>
<aside class="notes">
<p>
A LM defines a probability distribution by factoring according to the chain-rule
</p>

</aside>

<p>
<span class="fragment highlight-green">        \(P(w_1, w_2, ..., w_n)\) =
</span><span class="fragment highlight-green"> \(P(w_1|\text{<}bos\text{>})\)
</span><span class="fragment highlight-green"> \(* \prod_{i=1}^n P(w_{i+1}|w_1, ..., w_{i})\)
</span>
</p>

</section>
<section id="slide-org8b69d03">
<h3 id="org8b69d03">Models</h3>
<div class="outline-text-3" id="text-org8b69d03">
</div></section>
<section id="slide-org091863f">
<h4 id="org091863f">NGLM</h4>
<aside class="notes">
<p>
Introduce Markov Assumption
</p>

</aside>

<p>
\(P(w_t|\ldots)\) <span class="fragment fade-in"> \(\approx P(w_t|w_{t-(n+1)}, \ldots, w_{t-1})\) </span>
</p>

</section>
<section id="slide-orgfd91dd0">
<h4 id="orgfd91dd0">RNNLM</h4>

<div class="figure">
<p><object type="image/svg+xml" data="./img/rnnlm.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>

</section>
</section>
<section>
<section id="slide-org0a51798">
<h2 id="org0a51798"><span class="section-number-2">4</span> Experiment</h2>
<div class="outline-text-2" id="text-4">
</div></section>
<section id="slide-orgd0a60b4">
<h3 id="orgd0a60b4">Experimental Setup</h3>
<div class="outline-text-3" id="text-orgd0a60b4">
</div></section>
<section id="slide-orgd0b6182">
<h4 id="orgd0b6182">Difficulty</h4>
<aside class="notes">
<ul>
<li>There is an intrinsic difficulty to our experiment, which comes from the fact that we have to maximize comparability</li>
<li>Sources of divergence are:</li>

</ul>

</aside>
<p>
Maximize comparability of authentic and generated text
</p>
<ul>
<li class="fragment roll-in">Unequal training size per author for LMs</li>
<li class="fragment roll-in">Unequal training and test size per author for the attributor (important in AA)</li>
<li class="fragment roll-in">Authentic text has doc-level structure, LM-generated text does not</li>

</ul>

</section>
<section id="slide-org91bd6ec">
<h4 id="org91bd6ec">Proposed method</h4>
<ul>
<li class="fragment roll-in">Random even doc-level split (referred to as \(\alpha\) and \(\omega\) for simplicity)</li>
<li class="fragment roll-in">Create 20 fixed-size (5000w) docs per split by sampling sentences</li>
<li class="fragment roll-in">Sample a third set (\(\bar{\alpha}\)) from the author&rsquo;s LMs trained on \(\alpha\)</li>

</ul>

</section>
<section id="slide-org71e50eb">
<h4 id="org71e50eb">Attribution Experiments</h4>
<aside class="notes">
<p>
Better timing
</p>
<ul>
<li>Defines 5 experiments</li>
<li>Requires training only 3 classifiers (one per dataset)</li>
<li>Account for directionality effects</li>

</ul>

</aside>

<img src="./img/setup.svg">

</section>
<section id="slide-org461f3e7">
<h3 id="org461f3e7">Dataset</h3>
<aside class="notes">
<ul>
<li>Most of the team members currently work on Latin</li>
<li>Interesting baseline since Ecclesiastical Latin was mostly L2</li>
<li>More space for developing authorial style (more interesting authorial patterns)</li>
<li>Tematically, realatively homogeneous</li>

</ul>

</aside>
<ul>
<li class="fragment roll-in">Patrologia Latina (â©² 113M words)</li>
<li class="fragment roll-in">Ecclesiastical latin texts spanning 1000 years</li>
<li class="fragment roll-in">Homogeneous institutionalized literary language (L2 language)</li>

</ul>

</section>
<section >
<aside class="notes">
<ul>
<li>We only use those authors for which we had enough data for our experiment (18)</li>

</ul>

</aside>
<img src="./img/author_words_docs.svg">

</section>
<section id="slide-org443e832">
<h3 id="org443e832">Language Model Fitting</h3>
<div class="outline-text-3" id="text-org443e832">
</div></section>
<section id="slide-orgbe7b77f">
<h4 id="orgbe7b77f">NGLM</h4>
<ul>
<li class="fragment roll-in">N-gram order is set to 6</li>
<li class="fragment roll-in">Parameters estimated through MLE (no smoothing since only interested in generation)</li>

</ul>

</section>
<section id="slide-org7a7dc38">
<h4 id="org7a7dc38">RNNLM</h4>
<p>
Model definition
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment (roll-in)">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Parameter</th>
<th scope="col" class="org-right">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Embedding size</td>
<td class="org-right">24</td>
</tr>

<tr>
<td class="org-left">RNN Cell</td>
<td class="org-right">LSTM</td>
</tr>

<tr>
<td class="org-left">Hidden size</td>
<td class="org-right">200</td>
</tr>

<tr>
<td class="org-left">Hidden Layers</td>
<td class="org-right">2</td>
</tr>
</tbody>
</table>

</section>
<section >
<p>
Training
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment (roll-in)">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Parameter</th>
<th scope="col" class="org-right">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Batch size</td>
<td class="org-right">50</td>
</tr>

<tr>
<td class="org-left">Optimizer</td>
<td class="org-right">Adam (default params)</td>
</tr>

<tr>
<td class="org-left">Learning rate</td>
<td class="org-right">0.001</td>
</tr>

<tr>
<td class="org-left">Gradient norm clipping</td>
<td class="org-right">5.0</td>
</tr>

<tr>
<td class="org-left">Dropout</td>
<td class="org-right">0.3 (RNN output)</td>
</tr>

<tr>
<td class="org-left">Epochs</td>
<td class="org-right">50</td>
</tr>
</tbody>
</table>

</section>
<section >
<p>
Validation perplexity: <span class="fragment highlight-green"><strong>4.015 (Â± 0.183)</strong></span>
</p>

</section>
<section id="slide-orga7a10b1">
<h3 id="orga7a10b1">Attributor</h3>
<aside class="notes">
<ul>
<li>max-features: ordered by term-freq</li>
<li>small grid, since computationally expensive (5-fold CV + 7 experiments)</li>

</ul>

</aside>
<ul>
<li class="fragment roll-in">Linear SVM (scikit-learn) on tf-idf character {2,3,4}-grams</li>
<li class="fragment roll-in">No word-level features since RNN can produce unseen words</li>
<li class="fragment roll-in">Grid-search over parameters</li>

</ul>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides" class="fragment (roll-in)">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Parameter</th>
<th scope="col" class="org-left">Grid values</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Max-features</td>
<td class="org-left">5,000; 10,000; 15,000; 30,000</td>
</tr>

<tr>
<td class="org-left">C</td>
<td class="org-left">1; 10; 100; 1,000</td>
</tr>
</tbody>
</table>

</section>
</section>
<section>
<section id="slide-orgf6e60f7">
<h2 id="orgf6e60f7"><span class="section-number-2">5</span> Results</h2>
<p>
5-fold cross-validated scores per experiment
</p>

</section>
<section id="slide-org31dd1c5">
<h3 id="org31dd1c5">Numbers</h3>
<aside class="notes">
<p>
Description
</p>
<ul>
<li>&ldquo;Source&rdquo; refers to the type experiment</li>
<li>&ldquo;Experiment&rdquo; to the direction of training and testing</li>

</ul>
<p>
Results
</p>
<ul>
<li>Very small directionality effect (confirm no artifacts from split)</li>
<li>Training on generated data: drops considerably (both NGLM and RNNLM)</li>
<li>Training on real data: improvement on NGLM, still drop for the RNN</li>

</ul>

</aside>

<div class="table">

<!--l. 5--><p class="indent" >   <hr class="float"><div class="float" 
>

<!--tex4ht:inline--><div class="tabular">
 <table id="TBL-1" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-1-1g"><col 
id="TBL-1-1"><col 
id="TBL-1-2"><col 
id="TBL-1-3"><col 
id="TBL-1-4"><col 
id="TBL-1-5"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-1-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-1"  
class="td11">Source  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-2"  
class="td11">Experiment</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-3"  
class="td11"> F1  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-4"  
class="td11">  P  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-5"  
class="td11"> R  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-1"  
class="td11">Real     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha;,&omega; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-3"  
class="td11">0.833</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-4"  
class="td11">0.818</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-5"  
class="td11">0.869</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,&alpha; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-3"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-4"  
class="td11">0.795</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-5"  
class="td11">0.853</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-1"  
class="td11">NGLM  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-3"  
class="td11">0.706</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-4"  
class="td11">0.744</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-5"  
class="td11">0.750</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-3"  
class="td11">0.837</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-4"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-5"  
class="td11">0.881</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-1"  
class="td11">RNNLM</td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-3"  
class="td11">0.635</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-4"  
class="td11">0.701</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-5"  
class="td11">0.658</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;   </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-3"  
class="td11">0.724</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-4"  
class="td11">0.778</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-5"  
class="td11">0.775</td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-8-1"  
class="td11">       </td></tr></table></div>

   </div><hr class="endfloat" />
   </div>

</section>
<section id="slide-orgc560dff">
<h3 id="orgc560dff">Discussion</h3>
<div class="outline-text-3" id="text-orgc560dff">
</div></section>
<section id="slide-org1904bac">
<h4 id="org1904bac">Why does NGLM outperforms RNNLM in both setups (\(<\bar{\alpha},\omega>, <\omega,\bar{\alpha}>\))?</h4>
<aside class="notes">
<p>
The spectrum of style captured by ngram features is larger than just local features,
however local features make up for a large part of it, and reproducing it very accurately
(NGLM) gets you already far.
</p>

</aside>
<p class="fragment (roll-in)">
SVM uses very local features, NGLM reproduces very well the local distribution
</p>

</section>
<section >
<aside class="notes">
<p>
Use local information (ngrams) to visualize the effect of local features on both models
</p>
<ul>
<li>Compute a similarity matrix of generated and real authors on the basis of ngrams (2-4)</li>
<li>We use non-weighted Jaccard (intersection / union)</li>
<li>We expect a certain overlap for any author with theirselves (on the diagonal), and less overlap across authors</li>

</ul>

</aside>
<p>
LEXICAL OVERLAP: Mean-normalized ngram Jaccard-similarity across authors.
</p>

<p>
<span class="fragment fade-in"><strong>Character-level</strong><br/><img src="./img/jaccard_mean_char.svg"></span>
</p>

</section>
<section id="slide-org565a8bc">
<h4 id="org565a8bc">Why does NGLM outperform Real setup in (\(\omega\), \(\alpha\))?</h4>
<aside class="notes">
<p>
We haven&rsquo;t done any further analysis but judging on the basis of the previous viz
</p>

</aside>
<ul>
<li class="fragment roll-in">Prunning effect? Eliminating &ldquo;distractive&rdquo; features and enhancing those that are more relevant</li>
<li class="fragment roll-in">It might prove beneficial for actual AA</li>

</ul>


</section>
</section>
<section>
<section id="slide-org9b932c1">
<h2 id="org9b932c1"><span class="section-number-2">6</span> Self-learning (Data-augmentation) Experiments</h2>
<aside class="notes">
<p>
We were not satisfied, since RNNLM should have an advantage on modelling style, even though we only use very local feature to assess it.
In order to further test this, we designed a data-augmentation experiment in which we enrich authentic data with generated data
The idea is that if the augmentation improves over the baseline, the model has learned a richer model of the author style
</p>

</aside>

<ul>
<li class="fragment roll-in">Is there still some authorial signal in the RNNLM-generated data?</li>
<li class="fragment roll-in">Is there an effect of the long-term dependencies learned by the RNNLM on the stylistic properties of the generated data?</li>
<li class="fragment roll-in">If so, augmenting the authentic training data with RNNLM-generated data <span class="underline">could</span> yield attribution improvements</li>

</ul>


</section>
<section id="slide-orgf6a6dd6">
<h3 id="orgf6a6dd6">Experiment</h3>
<aside class="notes">
<p>
For each author, concatenate authentic document collection with the generated one.
</p>

</aside>

<p class="fragment (roll-in)">
\(<\alpha+\bar{\alpha}, \omega>\)
</p>

</section>
<section id="slide-orgefe530f">
<h3 id="orgefe530f">Numbers</h3>
<aside class="notes">
<ul>
<li>NGLM increases with respect to its baseline, but not over the real baseline</li>
<li>RNNLM increases (even over the &lt;$&alpha;, &omega;$&gt; baseline)</li>

</ul>

</aside>

<div id="table-full">
<div class="table">

<!--l. 5--><p class="indent" >   <hr class="float"><div class="float" 
>

<!--tex4ht:inline--><div class="tabular">
 <table id="TBL-1" class="tabular" 
cellspacing="0" cellpadding="0"  
><colgroup id="TBL-1-1g"><col 
id="TBL-1-1"><col 
id="TBL-1-2"><col 
id="TBL-1-3"><col 
id="TBL-1-4"><col 
id="TBL-1-5"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-1-1-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-1"  
class="td11">Source  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-1-2"  
class="td11">Experiment  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-3"  
class="td11"> F1  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-4"  
class="td11">  P  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-1-5"  
class="td11"> R  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-2-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-1"  
class="td11">Real     </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-2-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha;,&omega; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-3"  
class="td11">0.833</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-4"  
class="td11">0.818</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-2-5"  
class="td11">0.869</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-3-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-3-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,&alpha; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-3"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-4"  
class="td11">0.795</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-3-5"  
class="td11">0.853</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-4-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-1"  
class="td11">NGLM  </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-4-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha; </span>+ <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;</span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-3"  
class="td11">0.814</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-4"  
class="td11">0.809</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-4-5"  
class="td11">0.850</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-5-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-5-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-3"  
class="td11">0.706</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-4"  
class="td11">0.744</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-5-5"  
class="td11">0.750</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-6-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-6-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-3"  
class="td11">0.837</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-4"  
class="td11">0.811</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-6-5"  
class="td11">0.881</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-7-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-1"  
class="td11">RNNLM</td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-7-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &alpha; </span>+ <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;</span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-3"  
class="td11">0.872</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-4"  
class="td11">0.878</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-7-5"  
class="td11">0.892</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-8-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-8-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-8-2"  
class="td11"><span 
class="cmmi-10">&#x003C;</span> <span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span><span 
class="cmmi-10">,&omega; &#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-8-3"  
class="td11">0.635</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-8-4"  
class="td11">0.701</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-8-5"  
class="td11">0.658</td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-9-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-9-1"  
class="td11">       </td><td  style="white-space:nowrap; text-align:left;" id="TBL-1-9-2"  
class="td11"><span 
class="cmmi-10">&#x003C; &omega;,</span><span class="bar-css"><span 
class="cmmi-10">&alpha;</span></span> <span 
class="cmmi-10">&#x003E;     </span></td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-9-3"  
class="td11">0.724</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-9-4"  
class="td11">0.778</td><td  style="white-space:nowrap; text-align:center;" id="TBL-1-9-5"  
class="td11">0.775</td>

</tr><tr  
 style="vertical-align:baseline;" id="TBL-1-10-"><td  style="white-space:nowrap; text-align:left;" id="TBL-1-10-1"  
class="td11">       </td></tr></table></div>

   </div><hr class="endfloat" />
   </div>
</div>

</section>
<section id="slide-orgf3a17a9">
<h3 id="orgf3a17a9">Discussion</h3>
<aside class="notes">
<p>
To summarize the argument
</p>

</aside>
<p class="fragment (roll-in)">
-&gt; The long-term dependencies prove beneficial (not redundant)
</p>
<p class="fragment (roll-in)">
-&gt; (Evidence for) RNNLM better modelling stylistic variation in the original distribution
</p>

</section>
</section>
<section>
<section id="slide-orgc20eef1">
<h2 id="orgc20eef1"><span class="section-number-2">7</span> Conclusion</h2>
<aside class="notes">
<p>
Shortcomings:
</p>
<ul>
<li>Grid-search instead of random-search</li>
<li>Further fine-tuning of the networks (pretraining + overfitting?)</li>
<li>More compact models (CLMs (VAEs), multiheaded, &#x2026;)</li>

</ul>

</aside>

<ul>
<li>LMs seem to capture stylistic properties to a certain extent</li>
<li>Arguably RNNLMs are richer models (based on the augmentation experiments)</li>
<li>More global attributors still needed. Stylistic evaluation still too local</li>
<li>Further exploration of Data Prunning (NGLM) &amp; Data augmentation (RNNLM) for AA</li>

</ul>

</section>
</section>
<section>
<section id="slide-org007d1b5">
<h2 id="org007d1b5"><span class="section-number-2">8</span> Thank you for your attention!</h2>

</section>
</section>
<section>
<section id="slide-org63432c9">
<h2 id="org63432c9"><span class="section-number-2">9</span> Plots</h2>
</section>
<section >
<aside class="notes">
<ul>
<li>For 3 authors, we take real and generated documents</li>
<li>We represent the documents using 150 most frequente char ngrams</li>
<li>Apply PCA to visualize the documents in space (for clustering)</li>
<li>We observe that this representation based on local features puts real and NGLM-generated text together</li>

</ul>

</aside>
<p>
DOC-LEVEL PCA: <b>NGLM</b> (150 most-freq ngrams doc-representation)
</p>
<img src="./img/nglm_pca.svg">

</section>
<section >
<aside class="notes">
<ul>
<li>Clustering based on local features separates real and RNNLM-generated in some cases</li>
<li>Reveals certain fuzzyness in the RNNLM-generated text</li>

</ul>

</aside>
<p>
DOC-LEVEL PCA: <b>RNNLM</b> (150 most-freq ngrams doc-representation)
</p>
<img src="./img/rnnlm_pca.svg">

</section>
<section >
<aside class="notes">
<ul>
<li>Effect seems to be skewing the f1 distribution towards the top</li>
<li>Rescueing some helplessly mislabeled authors (helping the attribution of some guys)</li>

</ul>

</aside>
<img src="./img/f1_sampled.svg">
</section>
</section>
</div>
</div>
<script src="../externals/reveal.js/lib/js/head.min.js"></script>
<script src="../externals/reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: true,
center: true,
slideNumber: 'c',
rollingLinks: true,
keyboard: true,
overview: true,
width: 1200,
height: 800,
margin: 0.05,
minScale: 0.50,
maxScale: 2.50,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'slide', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'fast',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: '../externals/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
 { src: '../externals/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '../externals/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '../externals/reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: '../externals/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
});
</script>
</body>
</html>
