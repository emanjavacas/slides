<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Improving Lemmatization of Non-Standard Languages with Joint Learning</title>
<meta name="author" content="(Enrique Manjavacas & Ákos Kádár & Mike Kestemont)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="../externals/reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="../externals/reveal.js/css/theme/sky.css" id="theme"/>

<link rel="stylesheet" href="./extra.css"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = '../externals/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1 class="title">Improving Lemmatization of Non-Standard Languages with Joint Learning</h1><h2 class="author">Enrique Manjavacas &amp; Ákos Kádár &amp; Mike Kestemont</h2>
</section>

<section>
<section id="slide-orgc839b3d">
<h2 id="orgc839b3d"><span class="section-number-2">1</span> Lemmatization</h2>
<div class="outline-text-2" id="text-1">
</div>
</section>
</section>
<section>
<section id="slide-org690ac03">
<h3 id="org690ac03">Motivation</h3>
<ul>
<li class="fragment roll-in">Less than solved for morphologically rich or/and low-resource languages</li>
<li class="fragment roll-in">Important for downstream tasks:
<ul>
<li>Other NLP core tasks</li>
<li>Text classification, Stylometry</li>
<li>Topic Modelling</li>

</ul></li>

</ul>

</section>
</section>
<section>
<section id="slide-orgc9bba32">
<h3 id="orgc9bba32">What makes lemmatization difficult?</h3>
<div class="outline-text-3" id="text-orgc9bba32">
</div>
</section>
<section id="slide-org884aae0">
<h4 id="org884aae0">Morphological variation</h4>
<p>
Different <b>inflectional</b> morphological processes
</p>

<ul>
<li class="fragment roll-in"><b>Agglutination</b>:
<ul>
<li class="fragment roll-in">el[ler][imiz][in] (of our hands) -&gt; el (hand)</li>

</ul></li>
<li class="fragment roll-in"><b>Fusion</b> (infixation): 
<ul>
<li class="fragment roll-in">salt[a][ba][s] (he/she was jumping) -&gt; [salt][ar] (jumped)</li>

</ul></li>
<li class="fragment roll-in"><b>Introflexion (ablaut)</b>: 
<ul>
<li class="fragment roll-in">kutub (books) -&gt; kitab (book)</li>
<li class="fragment roll-in">swam -&gt; swim</li>

</ul></li>

</ul>

</section>
<section id="slide-org76ee711">
<h4 id="org76ee711">Token-lemma ambiguity</h4>
<ul>
<li class="fragment roll-in">Spanish: estado -&gt; (estar, estado)</li>
<li class="fragment roll-in">English: living -&gt; (living, live)</li>
<li class="fragment roll-in">English: &rsquo;s -&gt; (be, &rsquo;s, have)</li>
<li class="fragment roll-in">Medieval French: que -&gt; (qui, que1, que2, que3, que4)</li>

</ul>

</section>
<section >
<ul>
<li>Affected by annotation conventions</li>
<li class="fragment roll-in">Results from orthographical variation (e.g. abbreviations)</li>
<li class="fragment roll-in">Inversely correlated with morphological complexity</li>

</ul>

</section>
<section id="slide-orgb033043">
<h4 id="orgb033043">Spelling variation</h4>
<ul>
<li class="fragment roll-in">Middle Low German: beth -&gt; (bet, bēde, bethleme, bat, gôt)</li>
<li class="fragment roll-in">Middle Dutch: hoer -&gt; (haar, zij, hun, zich, oor, horen)</li>

</ul>

</section>
<section >

<ul>
<li class="fragment roll-in">Increases token-lemma ambiguity spelling variation (conflates unrelated forms)</li>
<li class="fragment roll-in">Reduces the amount of evidence for a lemma (lowers token/lemma ratio)</li>

</ul>

</section>
</section>
<section>
<section id="slide-orgfe8f344">
<h2 id="orgfe8f344"><span class="section-number-2">2</span> Data-driven Paradigms</h2>
<div class="outline-text-2" id="text-2">
</div>
</section>
</section>
<section>
<section id="slide-org89eb535">
<h3 id="org89eb535">Edit trees</h3>

<div class="figure">
<p><img src="./img/edit-tree.png" alt="edit-tree.png" />
</p>
</div>

</section>
<section id="slide-orgf7a7efe">
<h4 id="orgf7a7efe">Representative work</h4>
<ul>
<li><a href="http://www.aclweb.org/anthology/W/W10/W10-14.pdf#page=95">Morfette (Chrupala 2008)</a></li>
<li><a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP272.pdf">Lemming (Mueller et al 2015)</a></li>
<li><a href="https://pdfs.semanticscholar.org/6aed/32124e761167332f1175909c6b0864e54bb3.pdf">Context Sensitive Lemmatization Using Two Successive Bidirectional Gated Recurrent Networks (Chakrabarty et al. 2017)</a></li>

</ul>

</section>
</section>
<section>
<section id="slide-org4ae70d0">
<h3 id="org4ae70d0">String-Transduction</h3>

<div class="figure">
<p><img src="./img/seq2seq.png" alt="seq2seq.png" />
</p>
</div>

</section>
<section id="slide-org029cb27">
<h4 id="org029cb27">Representative work</h4>
<ul>
<li><a href="http://aclweb.org/anthology/N18-1126">Context Sensitive Neural Lemmatization with Lematus (Bergmanis et al. 2017)</a></li>
<li><a href="https://arxiv.org/pdf/1808.03703.pdf">LemmaTag (Kondratyuk et al 2018)</a></li>

</ul>

</section>
</section>
<section>
<section id="slide-org9bd39e6">
<h2 id="org9bd39e6"><span class="section-number-2">3</span> Our work</h2>
<p>
Improve <b>Lemmatization</b> as <b>String-transduction</b> of <b>Non-standard</b> varieties with <b>Encoder-Decoder</b>
</p>

</section>
</section>
<section>
<section id="slide-org2d53449">
<h3 id="org2d53449">Datasets</h3>
<div class="outline-text-3" id="text-org2d53449">
</div>
</section>
<section id="slide-orgb7590e7">
<h4 id="orgb7590e7">Historical Languages</h4>

<div class="figure">
<p><img src="./img/hist_langs.png" alt="hist_langs.png" />
</p>
</div>

</section>
<section id="slide-orga29dd42">
<h4 id="orga29dd42">Standard Languages (from Universal Dependencies)</h4>

<div class="figure">
<p><img src="./img/UD_langs.png" alt="UD_langs.png" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-org33212f3">
<h3 id="org33212f3">Quantifying Spelling Variation</h3>
<ul>
<li class="fragment roll-in">Morphological word
<ul>
<li class="fragment roll-in"><code>pron(pers,1,sing,nominative,"ik")</code></li>

</ul></li>
<li class="fragment roll-in">&ldquo;Alloforms&rdquo;
<ul>
<li class="fragment roll-in">&ldquo;ic&rdquo;, &ldquo;jc&rdquo;, &ldquo;hic&rdquo;, &ldquo;ig&rdquo;, &ldquo;ik&rdquo;, &ldquo;ict&rdquo;, &#x2026;</li>

</ul></li>
<li class="fragment roll-in"><code>spelling-variation</code> \(\propto\) <code>#tokens/#morph-words</code></li>

</ul>

</section>
<section >
<p>
Morphological Complexity by Spelling Variation
</p>
<img src="./img/complexity-by-spelling.svg"/>

</section>
</section>
<section>
<section id="slide-org0f0a912">
<h3 id="org0f0a912">Model</h3>
<div class="outline-text-3" id="text-org0f0a912">
</div>
</section>
<section id="slide-orga94cb80">
<h4 id="orga94cb80">Recap: Standard Encoder-Decoder</h4>

<div class="figure">
<p><img src="./img/seq2seq.png" alt="seq2seq.png" />
</p>
</div>

</section>
<section id="slide-orge668366">
<h4 id="orge668366">Conditioning the decoder on jointly-learned sentence-level context vector</h4>

<div class="figure">
<p><img src="./img/sentence-encoder.png" alt="sentence-encoder.png" />
</p>
</div>

</section>
<section >

<p>
Is the training signal coming from the lemma decoder enough?
</p>

</section>
<section id="slide-orgcc743cd">
<h4 id="orgcc743cd">Joint Learning with a Bidirectional Language Model Loss</h4>
<p>
Inspection of LMs through auxiliary tasks shows that LMs internally model quite a deal of linguistic structure
</p>

</section>
<section >

<ul>
<li><a href="https://arxiv.org/abs/1802.05365">Embeddings from Language Models (ELMo)</a></li>
<li><a href="https://arxiv.org/abs/1801.06146">Universal Language Model Fine-tuning (ULMFiT)</a></li>
<li><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a></li>
<li><a href="https://arxiv.org/abs/1810.04805">BERT</a></li>

</ul>

</section>
<section >


<div class="figure">
<p><img src="./img/sentence-lm.png" alt="sentence-lm.png" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-orgee989e9">
<h2 id="orgee989e9"><span class="section-number-2">4</span> Results</h2>
<div class="outline-text-2" id="text-4">
</div>
</section>
</section>
<section>
<section id="slide-org857fe05">
<h3 id="org857fe05">Numbers</h3>
<div class="outline-text-3" id="text-org857fe05">
</div>
</section>
<section id="slide-org8556e27">
<h4 id="org8556e27">Historical Languages</h4>

<div class="figure">
<p><img src="./img/hist.png" alt="hist.png" />
</p>
</div>

</section>
<section >


<div class="figure">
<p><img src="./img/gysseling.png" alt="gysseling.png" />
</p>
</div>

</section>
<section >

<ul>
<li class="fragment roll-in">Efficient for historical languages (especially ambiguous tokens)</li>
<li class="fragment roll-in">Less efficient on unknown tokens</li>

</ul>

</section>
<section id="slide-org97c9d1f">
<h4 id="org97c9d1f">Standard Languages</h4>

<div class="figure">
<p><img src="./img/UD.png" alt="UD.png" />
</p>
</div>

</section>
<section >
<ul>
<li class="fragment roll-in">Efficient for highly fusional (B-S) and morphologically complex languages (F-U/T)</li>
<li class="fragment roll-in">Less efficient on unknown tokens</li>
<li class="fragment roll-in">On analytic and less morphologically complex languages (I/G) edit-tree approaches are very effective</li>

</ul>

</section>
</section>
<section>
<section id="slide-org60e1d10">
<h3 id="org60e1d10">Interpretations</h3>
</section>
<section >
<p>
Correlation between error reduction and ambiguity
</p>
<img src="./img/error-reduction-by-trees.svg">

</section>
<section id="slide-org72f8220">
<h4 id="org72f8220">How does the LM-loss help?</h4>
<img src="./img/probe.svg">

</section>
</section>
<section>
<section id="slide-org44178fa">
<h3 id="org44178fa">Future work</h3>
<ul>
<li class="fragment roll-in">Why not use training signal from POS-tags and morphological annotation?</li>
<li class="fragment roll-in">What about pre-training?</li>

</ul>

</section>
</section>
<section>
<section id="slide-org259e7fd">
<h2 id="org259e7fd"><span class="section-number-2">5</span> Questions?</h2>
</section>
</section>
</div>
</div>
<script src="../externals/reveal.js/lib/js/head.min.js"></script>
<script src="../externals/reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: true,
center: true,
slideNumber: 'c',
rollingLinks: true,
keyboard: true,
overview: true,
width: 1200,
height: 800,
margin: 0.05,
minScale: 0.50,
maxScale: 2.50,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'slide', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'fast',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: '../externals/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
 { src: '../externals/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '../externals/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: '../externals/reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: '../externals/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
});
</script>
</body>
</html>
