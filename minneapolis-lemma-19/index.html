<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Improving Lemmatization of Non-standard Languages with Joint-Learning</title>
<meta name="author" content="((bold (:begin 1 :end 22 :contents-begin 2 :contents-end 20 :post-blank 1 :parent #0) Enrique Manjavacas) (italic (:begin 22 :end 48 :contents-begin 23 :contents-end 46 :post-blank 1 :parent #0) (University of Antwerp)) (export-snippet (:back-end html :value <br> :begin 48 :end 62 :post-blank 1 :parent #0)) (bold (:begin 62 :end 75 :contents-begin 63 :contents-end 73 :post-blank 1 :parent #0) Ákos Kádár) (italic (:begin 75 :end 98 :contents-begin 76 :contents-end 96 :post-blank 1 :parent #0) (Tilburg University)) (export-snippet (:back-end html :value <br> :begin 98 :end 112 :post-blank 1 :parent #0)) (bold (:begin 112 :end 129 :contents-begin 113 :contents-end 127 :post-blank 1 :parent #0) Mike Kestemont) (italic (:begin 129 :end 154 :contents-begin 130 :contents-end 153 :post-blank 0 :parent #0) (University of Antwerp)))"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="file:///home/manjavacas/.emacs.d/lisp/reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="file:///home/manjavacas/.emacs.d/lisp/reveal.js/css/theme/solarized.css" id="theme"/>

<link rel="stylesheet" href="./extra.css"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'file:///home/manjavacas/.emacs.d/lisp/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1 class="title">Improving Lemmatization of Non-standard Languages with Joint-Learning</h1><h2 class="author"><b>Enrique Manjavacas</b> <i>(University of Antwerp)</i> <br> <b>Ákos Kádár</b> <i>(Tilburg University)</i> <br> <b>Mike Kestemont</b> <i>(University of Antwerp)</i></h2>
</section>


<section>
<section id="slide-org9ffcaf9">
<h2 id="org9ffcaf9"><span class="section-number-2">1</span> Lemmatization</h2>
<div class="outline-text-2" id="text-1">
</div>
</section>
</section>
<section>
<section id="slide-orgc56bdbd" data-background="#282A36">
<h3 id="orgc56bdbd">Task Definition</h3>
<aside class="notes">
<ul>
<li>A snippet from a sentence in PROIEL latin corpus (part of UD)</li>
<li>We care about the second column</li>
<li>Lemma: dictionary headword underlying the whole morphological paradigm</li>

</ul>

</aside>

<img src="./images/example_gradient.png" class="stretch"/>

</section>
</section>
<section>
<section id="slide-orgb5b7ea3">
<h3 id="orgb5b7ea3">Applications</h3>
<ul>
<li>Linking to dictionary</li>
<li>Text Classification (esp. for morphologically complex languages)</li>
<li>Stylometry</li>
<li>Topic Modeling (reduce vocabulary size)</li>

</ul>

</section>
</section>
<section>
<section id="slide-org1e4bc10">
<h3 id="org1e4bc10">Challenges</h3>
<ol>
<li class="fragment roll-in">Token-lemma disambiguation
<ul>
<li>e.g. &ldquo;living&rdquo; -&gt; &ldquo;living&rdquo;, &ldquo;live&rdquo; <code>(en)</code></li>
<li>e.g. &ldquo;estado&rdquo; -&gt; &ldquo;estar&rdquo;, &ldquo;estado&rdquo; <code>(es)</code></li>

</ul></li>
<li class="fragment roll-in">Morphological Complexity (variety of processes)
<ul>
<li>Agglutination: <i>el[ler][imiz][in]</i> (of our hands) -&gt; <i>el</i> (hand)</li>
<li>Fusion: <i>salt[a][ba][s]</i> (he/she was jumping) -&gt; <i>salt[ar]</i> (jumped)</li>
<li>Ablaut: <i>kutub</i> (books) -&gt; <i>kitab</i> (book)</li>

</ul></li>

</ol>

</section>
</section>
<section>
<section id="slide-orgeee8e6d">
<h3 id="orgeee8e6d">Historical Languages</h3>
<ul>
<li>Span a long historical period (e.g. middle ages)</li>
<li>Present high genre specificity (charters, medicine, history)</li>
<li>Lack a strong standard spelling system</li>

</ul>

</section>
<section id="slide-org3b6224e">
<h4 id="org3b6224e">Additional Challenging Aspect</h4>
<ol>
<li>Token-lemma disambiguation</li>
<li>Morphological Complexity</li>
<li><b>Orthographic Variation</b></li>

</ol>

</section>
<section id="slide-org303eb05" data-background="#F0F0F0">
<h4 id="org303eb05">Orthographic Variation Examples</h4>
<aside class="notes">
<ul>
<li>Middle dutch and low german corpora</li>
<li>relatively high entropy distributions of lemmas</li>
<li>contractions (du+er), (du+zij)</li>

</ul>

</aside>

<img src="./images/token-lemma.png" class="stretch"/>

</section>
<section id="slide-org9e84785">
<h4 id="org9e84785">Implications of Orthographic Variation for Lemmatization</h4>
<ul>
<li>Increases token-lemma ambiguities</li>
<li>Sparsifies evidence for token-lemma mappings (due to higher token/type ratio)</li>

</ul>

</section>
</section>
<section>
<section id="slide-org498f754">
<h2 id="org498f754"><span class="section-number-2">2</span> Architecture</h2>
<div class="outline-text-2" id="text-2">
</div>
</section>
</section>
<section>
<section id="slide-org3273417" data-background="#FFFFFF">
<h3 id="org3273417">Encoder-Decoder</h3>
<img src="images/encoder-decoder.png" class="stretch"/>

</section>
</section>
<section>
<section id="slide-orgdca21be" data-background="#FFFFFF">
<h3 id="orgdca21be">Modeling Sentential Context</h3>
<img src="images/sentence-encoder.png" class="stretch"/>

</section>
</section>
<section>
<section id="slide-org9bf5421" data-background="#FFFFFF">
<h3 id="org9bf5421">Improved Sentence Encodings (Contribution)</h3>
<img src="images/sentence-encoder_joint.png" class="stretch"/>

</section>
<section id="slide-org0c4933b">
<h4 id="org0c4933b">Joint Learning</h4>
<aside class="notes">
<ul>
<li>lemma encoder-decoder loss</li>
<li>LM loss, predict w based on the hidden forward encoding at the previous token</li>
<li>LM loss, predict w based on the hidden backward encoding at the next token</li>

</ul>

</aside>

<p class="fragment (roll-in)">
\(P_{lemma}(l^t_{1\ldots n}|w^t) = P(l_n|w^t, s^t) \cdot P(l^t_{1\ldots n-1}|w^t, s^t)\)
</p>
<p class="fragment (roll-in)">
\(P_{LM}(w^t) = \boldsymbol{\gamma_{fwd}} P(w^t|s^{t-1}_{fwd}) + \boldsymbol{\gamma_{bwd}} P(w^t|s^{t+1}_{bwd})\)
</p>
<p class="fragment (roll-in)">
\(P = P_{lemma} + \boldsymbol{\beta} P_{LM}\)
</p>

<ul>
<li class="fragment roll-in">Decrease \(\boldsymbol{\gamma_{fwd}}\) and \(\boldsymbol{\gamma_{bwd}}\) based on dev accuracy</li>
<li class="fragment roll-in">Use \(\boldsymbol{\beta}\) to rescale LM loss</li>

</ul>

</section>
</section>
<section>
<section id="slide-org851e285">
<h2 id="org851e285"><span class="section-number-2">3</span> Corpus</h2>
<div class="outline-text-2" id="text-3">
</div>
</section>
</section>
<section>
<section id="slide-org0d48162">
<h3 id="org0d48162">Historical Languages</h3>
<ul>
<li>Selection of open-source 9 corpora</li>
<li>Language coverage:
<ul>
<li>Latin</li>
<li>Middle-low German</li>
<li>Medieval French</li>
<li>Historical Slovene</li>
<li>Medieval Dutch (Corpus Gysseling)</li>

</ul></li>

</ul>

</section>
</section>
<section>
<section id="slide-org308f839">
<h3 id="org308f839">Standard Languages</h3>
<p>
20 Languages from the Universal Dependencies
</p>

</section>
</section>
<section>
<section id="slide-orga0f07a4">
<h3 id="orga0f07a4">Statistics</h3>
<aside class="notes">
<ul>
<li>Some statistics where we see large variance in terms of size</li>

</ul>

</aside>

<style>
.container{ display: flex; }
.col{ flex: 1; }
</style>

<div class="container stretch">
  <div class="col">
  <img src="images/dataset_stats_hist.png" class="stretch"/>
  </div>
  <div class="col">
      <img src="images/dataset_stats_standard.png" class="stretch"/>
  </div>
</div>

</section>
</section>
<section>
<section id="slide-org5b3717d">
<h2 id="org5b3717d"><span class="section-number-2">4</span> Baselines</h2>
<ul>
<li>Strongest non-neural data-driven lemmatizers</li>
<li>Based on edit-tree induction</li>

</ul>

</section>
</section>
<section>
<section id="slide-org6161da7" data-background="#FFFFFF">
<h3 id="org6161da7">Edit-tree Induction</h3>
<img src="images/edit-tree.png" class="" />


</section>
<section id="slide-org4b27758">
<h4 id="org4b27758">Morfette (Chrupała et al. 2008)</h4>
<p>
Beam-search decoding of edit trees and POS <a href="https://github.com/gchrupala/morfette">https://github.com/gchrupala/morfette</a>
</p>

</section>
<section id="slide-org74b80f4">
<h4 id="org74b80f4">Lemming (Cotterell et al. 2015)</h4>
<p>
Second-order CRF decoding of edit-trees and POS <a href="http://cistern.cis.lmu.de/lemming/">http://cistern.cis.lmu.de/lemming/</a>
</p>

</section>
</section>
<section>
<section id="slide-orgc94dcf1">
<h2 id="orgc94dcf1"><span class="section-number-2">5</span> Evaluation</h2>
<ul>
<li>Accuracy of <b>known</b>, <b>unknown</b> and <b>ambiguous</b> tokens</li>
<li>(Un)known &amp; ambiguous is empirically determined based on train/dev split</li>

</ul>

</section>
</section>
<section>
<section id="slide-org0afeafb">
<h2 id="org0afeafb"><span class="section-number-2">6</span> Results</h2>
<div class="outline-text-2" id="text-6">
</div>
</section>
</section>
<section>
<section id="slide-orgabd8638" data-background="#FFFFFF">
<h3 id="orgabd8638">Historical Languages</h3>
<aside class="notes">
<ul>
<li>Plain is already better</li>
<li>Sentence context pushes it by almost 2 points</li>
<li>LM has an edge, helps in particular at disambiguating</li>

</ul>

</aside>

<img src="images/historical.png" class=""/>

</section>
</section>
<section>
<section id="slide-org4c39d7a" data-background="#FFFFFF">
<h3 id="org4c39d7a">Standard Languages</h3>
<aside class="notes">
<ul>
<li>LM wins overall</li>
<li>However, edit-tree has an edge on ambiguous and unknown</li>
<li>Suspicion: Numbers depend on morphological typology</li>

</ul>

</aside>

<img src="images/UD.png" class=""/>

</section>
<section id="slide-orgc34b463">
<h4 id="orgc34b463">How informative is averaging over typologically different languages?</h4>
<p>
Different inductive biases may benefit some languages more than others
</p>

</section>
<section id="slide-org43dc2ae">
<h4 id="org43dc2ae">Results by Morphological Typology</h4>
<aside class="notes">
<ul>
<li>Type 1: Balto-slavic: strongly suffixing, complex nominal morphology</li>
<li>Type 2: Uralic &amp; Altaic: agglutinative, monoexponential case, low ambiguity</li>
<li>Type 3: Western European: tendency towards synthetic morphology</li>

</ul>

</aside>

<p>
<b>Type 1</b> <code>bg</code>, <code>cs</code>, <code>lv</code>, <code>ru</code>, <code>sl</code>
</p>

<p>
<b>Type 2</b> <code>et</code>, <code>fi</code>, <code>hu</code>, <code>tr</code>
</p>

<p>
<b>Type 3</b> <code>de</code>, <code>en</code>, <code>es</code>, <code>fr</code>, <code>it</code>, <code>nb</code>
</p>

</section>
<section id="slide-orga479541" data-background="#FFFFFF">
<h4 id="orga479541"></h4>
<aside class="notes">
<ul>
<li>Type 3: Non-neural is really hard to beat</li>
<li>Type 2: Edit-tree only wins on ambiguous, of which there are really few</li>
<li>Type 1: Neural wins</li>

</ul>

</aside>

<img src="images/typology.png" class="stretch"/>

</section>
</section>
<section>
<section id="slide-org0fcc474">
<h2 id="org0fcc474"><span class="section-number-2">7</span> Discussion</h2>
<div class="outline-text-2" id="text-7">
</div>
</section>
</section>
<section>
<section id="slide-org631a155">
<h3 id="org631a155">Limits of edit-tree induction</h3>
<aside class="notes">
<ul>
<li>Very good inductive bias for western european languages</li>
<li>Less efficient in other cases, especially historical languages</li>

</ul>

</aside>

<img src="images/error-reduction-by-trees1.png" class="stretch"/>

<p>
Error reduction of best neural vs best tree-induction by #Trees (Spearman R=0.79)
</p>

</section>
</section>
<section>
<section id="slide-org2df0cef">
<h3 id="org2df0cef">How does joint LM learning help</h3>
<aside class="notes">
<p>
Visualizing the intuition that joint learning helps resolving ambiguities
</p>

</aside>

<img src="images/error-reduction-by-ambiguity1.png" class="stretch"/>

<p>
Error reduction of SentLM vs Sent by Ambiguity (Spearman R=0.53)
</p>

</section>
</section>
<section>
<section id="slide-org1c09de6" data-background="#FFFFFF">
<h3 id="org1c09de6">Why does it help?</h3>
<img src="images/probing.png" class=""/>

<p>
Diagnostic classifiers trained on frozen encodings to predict morphology
</p>

</section>
</section>
<section>
<section id="slide-orgb9c530d">
<h2 id="orgb9c530d"><span class="section-number-2">8</span> Conclusions</h2>
<ul>
<li>Historical Languages pose additional difficulties to lemmatizers</li>
<li>Edit-trees are challenged by spelling variation</li>
<li>Improvements can be gained by fine-tuning the sentence encodings</li>
<li>Learnt encodings reflect morphological information (which is costly)</li>

</ul>

</section>
</section>
<section>
<section id="slide-orgf47b36b">
<h2 id="orgf47b36b"><span class="section-number-2">9</span> Thank you</h2>
<ul>
<li>Download &amp; Preprocessing Scripts: <a href="https://www.github.com/emanjavacas/pie-data">https://www.github.com/emanjavacas/pie-data</a></li>
<li>Sequence Labeling Framework: <a href="https://www.github.com/emanjavacas/pie">https://www.github.com/emanjavacas/pie</a></li>
<li>This presentation: <a href="https://emanjavacas.github.io/slides-content/minneapolis19">https://emanjavacas.github.io/slides-content/minneapolis19</a></li>

</ul>
</section>
</section>
</div>
</div>
<script src="file:///home/manjavacas/.emacs.d/lisp/reveal.js/lib/js/head.min.js"></script>
<script src="file:///home/manjavacas/.emacs.d/lisp/reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: true,
center: true,
slideNumber: 'c',
rollingLinks: false,
keyboard: true,
overview: true,
width: 1200,
height: 800,
margin: 0.05,
minScale: 0.50,
maxScale: 2.50,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'slide', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'fast',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'file:///home/manjavacas/.emacs.d/lisp/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
 { src: 'file:///home/manjavacas/.emacs.d/lisp/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'file:///home/manjavacas/.emacs.d/lisp/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'file:///home/manjavacas/.emacs.d/lisp/reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: 'file:///home/manjavacas/.emacs.d/lisp/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
});
</script>
</body>
</html>
